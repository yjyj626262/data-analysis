{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMaS2EjAdFWS5lNlnUXkEwr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 데이터 불러오기"],"metadata":{"id":"2QYdjR7NuQqw"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CJl151k6f8G","executionInfo":{"status":"ok","timestamp":1704700071638,"user_tz":-540,"elapsed":18707,"user":{"displayName":"문영재","userId":"17347162447709080908"}},"outputId":"2f663c2e-c72c-4d83-faf1-cb11bfff6d11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["normal = np.load('/content/drive/MyDrive/데이터/파/train/파_정상_224_color.npy')\n","disease = np.load('/content/drive/MyDrive/데이터/파/train/파_질병_224_color.npy')\n","expend = np.load('/content/drive/MyDrive/데이터/파/train/파_증강_224_color.npy')\n","diseases = np.concatenate((disease, expend), axis=0)\n","X_train2 = np.concatenate((normal, diseases), axis=0)\n","labels = pd.read_csv('/content/drive/MyDrive/데이터/파/train/[라벨]파.csv')\n","if X_train2.shape[0]==labels.shape[0] :\n","    y_train = labels.loc[:,'disease']\n","else :\n","    print('길이가 같지 않습니다.')"],"metadata":{"id":"H-F7s0j16VL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ek8XEdi6E-sc","executionInfo":{"status":"ok","timestamp":1704703573685,"user_tz":-540,"elapsed":6,"user":{"displayName":"문영재","userId":"17347162447709080908"}},"outputId":"7f6dabdf-e881-42d9-97c0-a1badfc5b815"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0., 16., 17., 18.])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["y_train[y_train==16]=1\n","y_train[y_train==17]=2\n","y_train[y_train==18]=3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zwNUkFkkE9a7","executionInfo":{"status":"ok","timestamp":1704703573685,"user_tz":-540,"elapsed":5,"user":{"displayName":"문영재","userId":"17347162447709080908"}},"outputId":"c5aa53e8-36f5-41b1-bf40-23fd985e9011"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-725e9f02fb39>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  y_train[y_train==16]=1\n","<ipython-input-26-725e9f02fb39>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  y_train[y_train==17]=2\n","<ipython-input-26-725e9f02fb39>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  y_train[y_train==18]=3\n"]}]},{"cell_type":"markdown","source":["# 데이터셋 분리"],"metadata":{"id":"E648QWu_uVAv"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n","from tensorflow.keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_train2, y_train, test_size=0.2, random_state=42, stratify = y_train)\n","\n","\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"metadata":{"id":"CACAAJSw6icR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L546TqcUBge5","executionInfo":{"status":"ok","timestamp":1704703478238,"user_tz":-540,"elapsed":2,"user":{"displayName":"문영재","userId":"17347162447709080908"}},"outputId":"a988e76d-1a89-4891-aa5a-aae47acb9372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(36195, 224, 224, 3) (9049, 224, 224, 3) (36195, 4) (9049,)\n"]}]},{"cell_type":"code","source":["# 용량 제한 맞춘 수정본\n","from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Add, Input, Activation, ZeroPadding2D\n","\n","def input_layer(x):\n","    x = ZeroPadding2D(padding=(3, 3))(x)  # 230x230x3\n","    x = Conv2D(64, (7, 7), strides=(2, 2))(x) # 112x112x64\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = ZeroPadding2D(padding=(1,1))(x) # 114x114x64\n","    x = MaxPooling2D((3, 3), 2)(x) # 56 x 56 x 64\n","    return x\n","\n","def conv_layer1(x, out,layer):\n","    shortcut = x\n","\n","    for i in range(layer):\n","        x = Conv2D(out, (3, 3), strides=(1, 1), padding='same')(x)\n","        x = BatchNormalization()(x)\n","        x = Activation('relu')(x)\n","\n","        x = Add()([x, shortcut])\n","        x = Activation('relu')(x)\n","        shortcut = x\n","    return x\n","\n","def conv_layer2(x, out, layer):\n","\n","    for i in range(layer):\n","        if(i == 0):\n","            x = Conv2D(out, (1, 1), strides=(2, 2), padding='same')(x)\n","            x = BatchNormalization()(x)\n","            x = Activation('relu')(x)\n","            shortcut=x\n","\n","        else:\n","            x = Conv2D(out, (3, 3), strides=(1, 1), padding='same')(x)\n","            x = BatchNormalization()(x)\n","            x = Activation('relu')(x)\n","\n","            x = Add()([x, shortcut])\n","            x = Activation('relu')(x)\n","\n","            shortcut = x\n","\n","    return x\n","\n","\n","def resnet_light():\n","    inputs = Input(shape=(224, 224, 3))\n","\n","    x = input_layer(inputs)   # 56x56x64\n","    x = conv_layer1(x,64,3)   # 56x56x64\n","    x = conv_layer2(x,128,4)  # 28x28x128\n","    x = conv_layer2(x,256,5)  # 14x14x256\n","    x = conv_layer2(x,512,3)  # 7x7x512\n","\n","    x = GlobalAveragePooling2D()(x)  # 512\n","    x = Dense(1000)(x)\n","    output_tensor = Dense(4, activation='softmax')(x)\n","\n","    model = Model(inputs=inputs, outputs=output_tensor)\n","    return model"],"metadata":{"id":"ythq2IIiJbP8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델학습"],"metadata":{"id":"B7WsgIMpSTi-"}},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","from tensorflow.keras.metrics import Recall, Precision\n","model = resnet_light()\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy', Recall(), Precision()])\n","\n","\n","modelpath='/content/drive/MyDrive/작물별 모델/파/green_onion_model.keras'\n","checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n","early_stopping_callback = EarlyStopping(monitor='val_loss', patience=35)\n","\n","history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=32, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n","\n","loaded_model = load_model(modelpath)\n","\n","loss, accuracy, recall, precision = loaded_model.evaluate(X_test, y_test)\n","print(\"\\n Test Accuracy: %.4f\" % accuracy)\n","print(\"\\n Test Recall: %.4f\" % recall)\n","print(\"\\n Test Precision: %.4f\" % precision)"],"metadata":{"id":"I0cX89bloy5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import load_model\n","modelpath='/content/drive/MyDrive/작물별 모델/파/green_onion_model.keras'\n","loaded_model = load_model(modelpath)\n","\n","loss, accuracy, recall = loaded_model.evaluate(X_test, y_test)\n","print(\"\\n Test Accuracy: %.4f\" % accuracy)\n","print(\"\\n Test Recall: %.4f\" % recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TZS0POxVCsav","executionInfo":{"status":"ok","timestamp":1704703714427,"user_tz":-540,"elapsed":30851,"user":{"displayName":"문영재","userId":"17347162447709080908"}},"outputId":"61396dfa-90ae-4053-9932-3ec8a5cee4ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["283/283 [==============================] - 4s 13ms/step - loss: 0.0832 - accuracy: 0.9801 - recall_2: 0.9800\n","\n"," Test Accuracy: 0.9801\n","\n"," Test Recall: 0.9800\n"]}]},{"cell_type":"code","source":["import os,sys\n","from PIL import Image\n","def resize_and_crop(img_array,size):\n","    img = Image.fromarray(image_array)\n","    img_ratio = img.size[0] / float(img.size[1])\n","    ratio = size[0] / float(size[1])\n","\n","    if ratio > img_ratio:\n","        img = img.resize((size[0], int(round(size[0] * img.size[1] / img.size[0]))),\n","            Image.LANCZOS)\n","        box = (0, int(round((img.size[1] - size[1]) / 2)), img.size[0],\n","               int(round((img.size[1] + size[1]) / 2)))\n","        img = img.crop(box)\n","\n","    elif ratio < img_ratio:\n","        img = img.resize((int(round(size[1] * img.size[0] / img.size[1])), size[1]),\n","            Image.LANCZOS)\n","        box = (int(round((img.size[0] - size[0]) / 2)), 0,\n","                int(round((img.size[0] + size[0]) / 2)), img.size[1])\n","        img = img.crop(box)\n","\n","    else :\n","        img = img.resize((size[0], size[1]), Image.LANCZOS)\n","\n","    return img"],"metadata":{"id":"ZmPT_tBSXJq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install Pillow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBtnJOxTX_U6","executionInfo":{"status":"ok","timestamp":1703646416635,"user_tz":-540,"elapsed":4544,"user":{"displayName":"식물 약국","userId":"17347162447709080908"}},"outputId":"88630614-6250-40b1-a6bd-e54bfac8be6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"]}]},{"cell_type":"code","source":["image = Image.open('/content/KakaoTalk_20231227_120513713.jpg')\n","# 이미지를 numpy 배열로 변환\n","image_array = np.array(image)\n","output_size = (224, 224)\n","resized_img = resize_and_crop(image_array,output_size)\n","test = np.array(resized_img).reshape(224,224,3)\n","img = test\n","height = img.shape[0]\n","width = img.shape[1]\n","#create target array for gray scale\n","gray_image = np.zeros((height, width, 1), dtype=np.uint8)\n","\n","# 입력 이미지의 pixel 값 하나씩 불러서 변경\n","for h in range(height):\n","    for w in range(width):\n","        b = img[h, w, 0].astype(np.float32) # RGB의 Blue 값 입력받기\n","        g = img[h, w, 1].astype(np.float32) # RGB의 Green 값 입력받기\n","        r = img[h, w, 2].astype(np.float32) # RGB의 Red 값 입력받기\n","\n","        intensity = (b+g+r)/3               # RGB 채널의 값을 하나의 값으로 평균 내기\n","        gray_image[h, w, 0] = intensity     # target array에 값 저장\n","gray_image = gray_image.reshape(1,128,128,1)\n","loaded_model.predict(gray_image)"],"metadata":{"id":"gwRSlTlQXvyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703646465692,"user_tz":-540,"elapsed":2567,"user":{"displayName":"식물 약국","userId":"17347162447709080908"}},"outputId":"d903c83e-c1c7-4010-8a65-d3a837c32ed6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 3s 3s/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"BpRvNdxwZef-"},"execution_count":null,"outputs":[]}]}